<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hongjie Li</title>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-EWFQX2P75H"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

  </script>

  <meta name="author" content="Hongjie Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="msvalidate.01" content="1D6EAEB9C6558C0BB977413398D67E91" />
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/icon.png">
</head>

<body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:20%;max-width:20%">
                <img style="width:100%;max-width:100%" alt="profile photo" src="images/Personal/hli_0.jpg" class="hoverZoomLink">
              </td>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Hongjie Li</name>
                </p>
                <p>
                  I am a junior student in <a href="https://eecs.pku.edu.cn/" target="_blank">School of EECS</a>, <a href="https://www.pku.edu.cn" target="_blank">Peking University</a>. I'm also a member of the Zhi Class.
                  I am currently a student researcher in <a href="https://pku.ai" target="_blank">Cognitive Reasoning (CoRe) Lab</a> at PKU-IAI, advised by <a href="https://yzhu.io" target="_blank">Prof. Yixin Zhu</a>.
                  I am also a research volunteer in the General Vision Lab, <a href="https://bigai.ai" target="_blank">BIGAI</a>, and I'm grateful to be advised by <a href="https://siyuanhuang.com" target="_blank">Dr. Siyuan Huang</a>.
                </p>
                <p>
                  My research interests lie in 3D computer vision and graphics, including human-object/scene interaction (HOI/HSI), 3D scene understanding, and generative modeling. My long-term goal is to build algorithms that understanding the physical world from sensory perception, and empower reasoning in commonsense and interactions for embodied agents like robots and digital humans.
                </p>
                      More info:
                      <a href="mailto:lihongjie@stu.pku.edu.cn">Email</a>
                      &nbsp/&nbsp<a href="https://github.com/awfuact" target="_blank">Github</a>
                      &nbsp/&nbsp<a href="files/cv_latest.pdf" target="_blank">CV</a>
              </td>
            </tr>
          </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research</heading>
          </td>
        </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr>
        <td style="padding:20px;width:18px;vertical-align:middle"><img src='images/Research/cvpr24_trumans/teaser.jpg', width="300px"></td>
        <td style="padding:15px;width:80%;vertical-align:middle">
          <papertitle>Scaling Up Dynamic Human-Scene Interaction Modeling</papertitle>
          <br>
          <a href="https://jnnan.github.io/" target="_blank">Nan Jiang</a>*,
          <a href="https://zhiyuan-zhang0206.github.io/" target="_blank">Zhiyuan Zhang</a>*,
          <strong>Hongjie Li</strong>,
          <a href="https://shirleymaxx.github.io/" target="_blank">Xiaoxuan Ma</a>,
          <a href="https://silvester.wang/" target="_blank">Zan Wang</a>,
          <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
          <a href="https://tengyu.ai/" target="_blank">Tengyu Liu</a>,
          <a href="https://yzhu.io/" target="_blank">Yixin Zhu</a>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>CVPR</em>, 2024
          <font color="red"><b>(Highlight)</b></font>
          <br>
          <a href="https://arxiv.org/pdf/2403.08629.pdf" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://huggingface.co/spaces/jnnan/trumans/tree/main" target="_blank">[Code]</a>
          &nbsp
          <a href="" target="_blank">[Data]</a>
          &nbsp
          <a href="https://jnnan.github.io/trumans/" target="_blank">[Project]</a>
          &nbsp
          <a href="https://huggingface.co/spaces/jnnan/trumans" target="_blank">[Hugging Face]</a>
          <br>
          <abs>
            We introduce <i>TRUMANS</i> , an extensive MoCap Human-Scene Interaction (HSI) dataset capturing a wide array of human behaviors across 100 indoor scenes, noted for its diversity, quality, and scalability. We further develop a diffusion-based autoregressive method for the real-time generation of HSI, adaptable to any length and conditioned on 3D scenes and action labels.
          </abs>
        </td>
      </tr>

    </tbody></table>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Experience</heading>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <tr>
        <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/bigai.png", width="100px"></td>
        <td width="90%" valign="center">
          <b>Beijing Institute for General Artificial Intelligence (BIGAI)</b>, China
          <br> Sept 2023 - Present
          <br>
          <br> <b>Research volunteer</b>
          <br> Advisor: <a href="https://siyuanhuang.com">Dr. Siyuan Huang</a>
        </td>
      </tr>
      <tr>
        <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/core_lab.png", width="100px"></td>
        <td width="90%" valign="center">
          <b>Cognitive Reasoning (CoRe) Lab</b>, Institute for Artificial Intelligence, Peking University, China
          <br> Jan 2023 - Present
          <br>
          <br> <b>Research volunteer</b>
          <br> Advisor: <a href="http://yzhu.io">Prof. Yixin Zhu</a>
        </td>
      </tr>
      <tr>
        <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/pku.jpeg", width="100px"></td>
        <td width="90%" valign="center">
          <b>Peking University</b>, China
          <br> Aug 2021 - Present
          <br>
          <br> <b>Junior Student</b>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
          Updated on Mar 16, 2024.
          <br>
          Template from <a href="https://jonbarron.info/" style="text-align:right;font-size:small;" target="_blank">Jon Barron</a>. 
          Icons by <a href="https://www.flaticon.com/authors/freepik" style="text-align:right;font-size:small;" target="_blank">Freepik</a>.
          Technical support from <a style="font-size:small;" href="https://yuyangli.com">Yuyang Li</a>.
        </p>
        </td>
      </tr>
    </tbody></table>
  </td>
  </tr>
  </table>
</body>

</html>
